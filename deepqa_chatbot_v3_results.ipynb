{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepqa chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saqib-Mahmood/Neural-chatbot-with-attention/blob/master/deepqa_chatbot_v3_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMRNymZIQHh8",
        "colab_type": "code",
        "outputId": "f4e62a72-a0c0-410e-9a1b-bcff85834a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!git clone https://github.com/Conchylicultor/DeepQA"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepQA'...\n",
            "remote: Enumerating objects: 986, done.\u001b[K\n",
            "remote: Total 986 (delta 0), reused 0 (delta 0), pack-reused 986\u001b[K\n",
            "Receiving objects: 100% (986/986), 11.54 MiB | 16.32 MiB/s, done.\n",
            "Resolving deltas: 100% (577/577), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HY5Y4lCQN23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv DeepQA/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFwbZUlyQ0AX",
        "colab_type": "code",
        "outputId": "bec6988b-fce0-452f-b3dd-284d1d7f6479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTDOx_xsQYkB",
        "colab_type": "code",
        "outputId": "4948e1eb-1b3b-4ccf-c2e2-e1fa18509ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to DeepQA v0.1 !\n",
            "\n",
            "TensorFlow detected: v1.15.0\n",
            "Training samples not found. Creating dataset...\n",
            "Constructing full dataset...\n",
            "Extract conversations: 100% 83097/83097 [02:12<00:00, 624.83it/s]\n",
            "Loaded cornell: 59755 words, 221282 QA\n",
            "Filtering words (vocabSize = 40000 and wordCount > 1)...\n",
            "Saving dataset...\n",
            "Loaded cornell: 34069 words, 205566 QA\n",
            "Model creation...\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:145: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:155: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:161: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2019-12-09 17:22:42.037511: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/legacy_seq2seq/python/ops/seq2seq.py:363: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/core_rnn_cell.py:104: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:204: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:207: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:173: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:174: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-12-09 17:22:53.250487: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2019-12-09 17:22:53.251353: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d40d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-09 17:22:53.251396: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-09 17:22:53.257822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-09 17:22:53.397267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:53.398297: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d40bc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-09 17:22:53.398356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-12-09 17:22:53.400225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:53.401014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-09 17:22:53.422695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-09 17:22:53.676998: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-09 17:22:53.802855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-09 17:22:53.827893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-09 17:22:54.068734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-09 17:22:54.090039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-09 17:22:54.530057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-09 17:22:54.530386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:54.531372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:54.532079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-09 17:22:54.536349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-09 17:22:54.541280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-09 17:22:54.541358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-09 17:22:54.541374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-09 17:22:54.542936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:54.543841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-09 17:22:54.544531: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-09 17:22:54.544602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Initialize variables...\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:192: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING: No previous model found, starting from clean directory: /content/save/model\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:230: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Start training (press Ctrl+C to save and exit)...\n",
            "\n",
            "----- Epoch 1/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "Training:   0% 0/402 [00:00<?, ?it/s]2019-12-09 17:23:14.573421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "----- Step 100 -- Loss 5.44 -- Perplexity 230.38\n",
            "----- Step 200 -- Loss 5.38 -- Perplexity 217.83\n",
            "----- Step 300 -- Loss 5.27 -- Perplexity 195.19\n",
            "----- Step 400 -- Loss 5.33 -- Perplexity 207.27\n",
            "Training: 100% 402/402 [17:35<00:00,  2.25s/it]\n",
            "Epoch finished in 0:17:35.797033\n",
            "\n",
            "----- Epoch 2/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 500 -- Loss 5.16 -- Perplexity 174.25\n",
            "----- Step 600 -- Loss 5.11 -- Perplexity 165.05\n",
            "----- Step 700 -- Loss 5.04 -- Perplexity 154.76\n",
            "----- Step 800 -- Loss 4.93 -- Perplexity 138.51\n",
            "Training: 100% 402/402 [17:18<00:00,  2.25s/it]\n",
            "Epoch finished in 0:17:18.403180\n",
            "\n",
            "----- Epoch 3/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 900 -- Loss 5.10 -- Perplexity 163.28\n",
            "----- Step 1000 -- Loss 4.97 -- Perplexity 144.16\n",
            "----- Step 1100 -- Loss 4.97 -- Perplexity 144.01\n",
            "----- Step 1200 -- Loss 4.94 -- Perplexity 139.98\n",
            "Training: 100% 402/402 [17:18<00:00,  2.23s/it]\n",
            "Epoch finished in 0:17:18.483765\n",
            "\n",
            "----- Epoch 4/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 1300 -- Loss 4.93 -- Perplexity 138.33\n",
            "----- Step 1400 -- Loss 4.75 -- Perplexity 115.85\n",
            "----- Step 1500 -- Loss 4.90 -- Perplexity 134.76\n",
            "----- Step 1600 -- Loss 4.68 -- Perplexity 107.70\n",
            "Training: 100% 402/402 [17:17<00:00,  2.22s/it]\n",
            "Epoch finished in 0:17:17.299249\n",
            "\n",
            "----- Epoch 5/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 1700 -- Loss 4.41 -- Perplexity 82.05\n",
            "----- Step 1800 -- Loss 4.62 -- Perplexity 101.29\n",
            "----- Step 1900 -- Loss 4.39 -- Perplexity 80.83\n",
            "----- Step 2000 -- Loss 4.28 -- Perplexity 72.46\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [17:35<00:00,  2.33s/it]\n",
            "Epoch finished in 0:17:35.893545\n",
            "\n",
            "----- Epoch 6/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 2100 -- Loss 4.22 -- Perplexity 68.30\n",
            "----- Step 2200 -- Loss 4.17 -- Perplexity 64.43\n",
            "----- Step 2300 -- Loss 4.08 -- Perplexity 59.11\n",
            "----- Step 2400 -- Loss 4.02 -- Perplexity 55.54\n",
            "Training: 100% 402/402 [17:24<00:00,  2.23s/it]\n",
            "Epoch finished in 0:17:24.877179\n",
            "\n",
            "----- Epoch 7/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 2500 -- Loss 3.95 -- Perplexity 51.91\n",
            "----- Step 2600 -- Loss 3.95 -- Perplexity 52.17\n",
            "----- Step 2700 -- Loss 3.91 -- Perplexity 49.82\n",
            "----- Step 2800 -- Loss 3.92 -- Perplexity 50.52\n",
            "Training: 100% 402/402 [17:24<00:00,  2.32s/it]\n",
            "Epoch finished in 0:17:24.493201\n",
            "\n",
            "----- Epoch 8/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 2900 -- Loss 3.86 -- Perplexity 47.30\n",
            "----- Step 3000 -- Loss 3.80 -- Perplexity 44.52\n",
            "----- Step 3100 -- Loss 3.85 -- Perplexity 46.92\n",
            "----- Step 3200 -- Loss 3.87 -- Perplexity 47.71\n",
            "Training: 100% 402/402 [17:11<00:00,  2.26s/it]\n",
            "Epoch finished in 0:17:11.189540\n",
            "\n",
            "----- Epoch 9/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 3300 -- Loss 3.66 -- Perplexity 39.02\n",
            "----- Step 3400 -- Loss 3.61 -- Perplexity 37.08\n",
            "----- Step 3500 -- Loss 3.75 -- Perplexity 42.62\n",
            "----- Step 3600 -- Loss 3.69 -- Perplexity 39.91\n",
            "Training: 100% 402/402 [17:18<00:00,  2.25s/it]\n",
            "Epoch finished in 0:17:18.309177\n",
            "\n",
            "----- Epoch 10/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 3700 -- Loss 3.69 -- Perplexity 39.90\n",
            "----- Step 3800 -- Loss 3.70 -- Perplexity 40.46\n",
            "----- Step 3900 -- Loss 3.69 -- Perplexity 40.13\n",
            "----- Step 4000 -- Loss 3.69 -- Perplexity 39.95\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [17:22<00:00,  2.25s/it]\n",
            "Epoch finished in 0:17:22.836197\n",
            "\n",
            "----- Epoch 11/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 4100 -- Loss 3.55 -- Perplexity 34.71\n",
            "----- Step 4200 -- Loss 3.71 -- Perplexity 41.05\n",
            "----- Step 4300 -- Loss 3.57 -- Perplexity 35.56\n",
            "----- Step 4400 -- Loss 3.64 -- Perplexity 38.03\n",
            "Training: 100% 402/402 [17:17<00:00,  2.26s/it]\n",
            "Epoch finished in 0:17:17.950289\n",
            "\n",
            "----- Epoch 12/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 4500 -- Loss 3.61 -- Perplexity 37.14\n",
            "----- Step 4600 -- Loss 3.50 -- Perplexity 32.96\n",
            "----- Step 4700 -- Loss 3.65 -- Perplexity 38.64\n",
            "----- Step 4800 -- Loss 3.52 -- Perplexity 33.91\n",
            "Training: 100% 402/402 [17:16<00:00,  2.33s/it]\n",
            "Epoch finished in 0:17:16.967758\n",
            "\n",
            "----- Epoch 13/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 4900 -- Loss 3.51 -- Perplexity 33.40\n",
            "----- Step 5000 -- Loss 3.52 -- Perplexity 33.69\n",
            "----- Step 5100 -- Loss 3.50 -- Perplexity 33.17\n",
            "----- Step 5200 -- Loss 3.47 -- Perplexity 32.29\n",
            "Training: 100% 402/402 [17:22<00:00,  2.28s/it]\n",
            "Epoch finished in 0:17:22.724415\n",
            "\n",
            "----- Epoch 14/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 5300 -- Loss 3.41 -- Perplexity 30.29\n",
            "----- Step 5400 -- Loss 3.46 -- Perplexity 31.91\n",
            "----- Step 5500 -- Loss 3.49 -- Perplexity 32.81\n",
            "----- Step 5600 -- Loss 3.48 -- Perplexity 32.34\n",
            "Training: 100% 402/402 [17:21<00:00,  2.25s/it]\n",
            "Epoch finished in 0:17:21.672299\n",
            "\n",
            "----- Epoch 15/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 5700 -- Loss 3.40 -- Perplexity 29.85\n",
            "----- Step 5800 -- Loss 3.49 -- Perplexity 32.79\n",
            "----- Step 5900 -- Loss 3.34 -- Perplexity 28.09\n",
            "----- Step 6000 -- Loss 3.41 -- Perplexity 30.21\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [17:27<00:00,  2.28s/it]\n",
            "Epoch finished in 0:17:27.102805\n",
            "\n",
            "----- Epoch 16/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6100 -- Loss 3.31 -- Perplexity 27.26\n",
            "----- Step 6200 -- Loss 3.39 -- Perplexity 29.77\n",
            "----- Step 6300 -- Loss 3.33 -- Perplexity 27.95\n",
            "----- Step 6400 -- Loss 3.40 -- Perplexity 29.87\n",
            "Training: 100% 402/402 [16:25<00:00,  2.09s/it]\n",
            "Epoch finished in 0:16:25.896691\n",
            "\n",
            "----- Epoch 17/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6500 -- Loss 3.28 -- Perplexity 26.65\n",
            "----- Step 6600 -- Loss 3.27 -- Perplexity 26.21\n",
            "----- Step 6700 -- Loss 3.32 -- Perplexity 27.53\n",
            "----- Step 6800 -- Loss 3.30 -- Perplexity 27.24\n",
            "Training: 100% 402/402 [16:06<00:00,  2.09s/it]\n",
            "Epoch finished in 0:16:06.654837\n",
            "\n",
            "----- Epoch 18/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 6900 -- Loss 3.21 -- Perplexity 24.89\n",
            "----- Step 7000 -- Loss 3.16 -- Perplexity 23.52\n",
            "----- Step 7100 -- Loss 3.25 -- Perplexity 25.78\n",
            "----- Step 7200 -- Loss 3.30 -- Perplexity 27.08\n",
            "Training: 100% 402/402 [16:07<00:00,  2.09s/it]\n",
            "Epoch finished in 0:16:07.493233\n",
            "\n",
            "----- Epoch 19/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 7300 -- Loss 3.19 -- Perplexity 24.35\n",
            "----- Step 7400 -- Loss 3.20 -- Perplexity 24.60\n",
            "----- Step 7500 -- Loss 3.17 -- Perplexity 23.91\n",
            "----- Step 7600 -- Loss 3.19 -- Perplexity 24.25\n",
            "Training: 100% 402/402 [16:09<00:00,  2.10s/it]\n",
            "Epoch finished in 0:16:09.116136\n",
            "\n",
            "----- Epoch 20/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 7700 -- Loss 3.14 -- Perplexity 23.03\n",
            "----- Step 7800 -- Loss 3.15 -- Perplexity 23.40\n",
            "----- Step 7900 -- Loss 3.21 -- Perplexity 24.81\n",
            "----- Step 8000 -- Loss 3.26 -- Perplexity 26.01\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [16:11<00:00,  2.10s/it]\n",
            "Epoch finished in 0:16:11.943930\n",
            "\n",
            "----- Epoch 21/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 8100 -- Loss 3.16 -- Perplexity 23.52\n",
            "----- Step 8200 -- Loss 3.07 -- Perplexity 21.48\n",
            "----- Step 8300 -- Loss 3.11 -- Perplexity 22.38\n",
            "----- Step 8400 -- Loss 3.16 -- Perplexity 23.62\n",
            "Training: 100% 402/402 [16:09<00:00,  2.08s/it]\n",
            "Epoch finished in 0:16:09.415033\n",
            "\n",
            "----- Epoch 22/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 8500 -- Loss 3.07 -- Perplexity 21.46\n",
            "----- Step 8600 -- Loss 3.09 -- Perplexity 21.90\n",
            "----- Step 8700 -- Loss 3.06 -- Perplexity 21.23\n",
            "----- Step 8800 -- Loss 3.12 -- Perplexity 22.74\n",
            "Training: 100% 402/402 [15:57<00:00,  2.07s/it]\n",
            "Epoch finished in 0:15:57.111580\n",
            "\n",
            "----- Epoch 23/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 8900 -- Loss 3.02 -- Perplexity 20.47\n",
            "----- Step 9000 -- Loss 3.00 -- Perplexity 20.00\n",
            "----- Step 9100 -- Loss 3.06 -- Perplexity 21.31\n",
            "----- Step 9200 -- Loss 3.10 -- Perplexity 22.09\n",
            "Training: 100% 402/402 [15:50<00:00,  2.05s/it]\n",
            "Epoch finished in 0:15:50.101229\n",
            "\n",
            "----- Epoch 24/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 9300 -- Loss 3.04 -- Perplexity 20.95\n",
            "----- Step 9400 -- Loss 3.02 -- Perplexity 20.43\n",
            "----- Step 9500 -- Loss 2.96 -- Perplexity 19.27\n",
            "----- Step 9600 -- Loss 3.10 -- Perplexity 22.14\n",
            "Training: 100% 402/402 [15:45<00:00,  2.03s/it]\n",
            "Epoch finished in 0:15:45.518570\n",
            "\n",
            "----- Epoch 25/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 9700 -- Loss 2.89 -- Perplexity 17.96\n",
            "----- Step 9800 -- Loss 2.97 -- Perplexity 19.47\n",
            "----- Step 9900 -- Loss 3.06 -- Perplexity 21.29\n",
            "----- Step 10000 -- Loss 2.94 -- Perplexity 18.96\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [15:41<00:00,  2.02s/it]\n",
            "Epoch finished in 0:15:41.559125\n",
            "\n",
            "----- Epoch 26/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 10100 -- Loss 2.86 -- Perplexity 17.39\n",
            "----- Step 10200 -- Loss 2.85 -- Perplexity 17.36\n",
            "----- Step 10300 -- Loss 2.88 -- Perplexity 17.84\n",
            "----- Step 10400 -- Loss 2.98 -- Perplexity 19.65\n",
            "Training: 100% 402/402 [15:30<00:00,  2.01s/it]\n",
            "Epoch finished in 0:15:30.856642\n",
            "\n",
            "----- Epoch 27/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 10500 -- Loss 2.85 -- Perplexity 17.33\n",
            "----- Step 10600 -- Loss 2.89 -- Perplexity 18.03\n",
            "----- Step 10700 -- Loss 2.90 -- Perplexity 18.09\n",
            "----- Step 10800 -- Loss 2.92 -- Perplexity 18.45\n",
            "Training: 100% 402/402 [15:34<00:00,  2.03s/it]\n",
            "Epoch finished in 0:15:34.733896\n",
            "\n",
            "----- Epoch 28/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 10900 -- Loss 2.82 -- Perplexity 16.77\n",
            "----- Step 11000 -- Loss 2.85 -- Perplexity 17.36\n",
            "----- Step 11100 -- Loss 2.96 -- Perplexity 19.21\n",
            "----- Step 11200 -- Loss 2.85 -- Perplexity 17.28\n",
            "Training: 100% 402/402 [15:31<00:00,  2.00s/it]\n",
            "Epoch finished in 0:15:31.458963\n",
            "\n",
            "----- Epoch 29/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 11300 -- Loss 2.81 -- Perplexity 16.56\n",
            "----- Step 11400 -- Loss 2.84 -- Perplexity 17.16\n",
            "----- Step 11500 -- Loss 2.81 -- Perplexity 16.55\n",
            "----- Step 11600 -- Loss 2.89 -- Perplexity 18.07\n",
            "Training: 100% 402/402 [15:20<00:00,  2.00s/it]\n",
            "Epoch finished in 0:15:20.455439\n",
            "\n",
            "----- Epoch 30/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 11700 -- Loss 2.76 -- Perplexity 15.87\n",
            "----- Step 11800 -- Loss 2.89 -- Perplexity 17.94\n",
            "----- Step 11900 -- Loss 2.71 -- Perplexity 15.07\n",
            "----- Step 12000 -- Loss 2.84 -- Perplexity 17.06\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [15:22<00:00,  2.00s/it]\n",
            "Epoch finished in 0:15:22.764899\n",
            "\n",
            "----- Epoch 31/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 12100 -- Loss 2.72 -- Perplexity 15.23\n",
            "----- Step 12200 -- Loss 2.76 -- Perplexity 15.84\n",
            "----- Step 12300 -- Loss 2.83 -- Perplexity 16.98\n",
            "----- Step 12400 -- Loss 2.73 -- Perplexity 15.26\n",
            "Training: 100% 402/402 [15:26<00:00,  2.00s/it]\n",
            "Epoch finished in 0:15:26.173757\n",
            "\n",
            "----- Epoch 32/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 12500 -- Loss 2.73 -- Perplexity 15.31\n",
            "----- Step 12600 -- Loss 2.74 -- Perplexity 15.43\n",
            "----- Step 12700 -- Loss 2.76 -- Perplexity 15.77\n",
            "----- Step 12800 -- Loss 2.69 -- Perplexity 14.71\n",
            "Training: 100% 402/402 [15:21<00:00,  1.99s/it]\n",
            "Epoch finished in 0:15:21.056254\n",
            "\n",
            "----- Epoch 33/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 12900 -- Loss 2.63 -- Perplexity 13.89\n",
            "----- Step 13000 -- Loss 2.68 -- Perplexity 14.65\n",
            "----- Step 13100 -- Loss 2.65 -- Perplexity 14.19\n",
            "----- Step 13200 -- Loss 2.71 -- Perplexity 15.06\n",
            "Training: 100% 402/402 [15:25<00:00,  2.01s/it]\n",
            "Epoch finished in 0:15:25.160216\n",
            "\n",
            "----- Epoch 34/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 13300 -- Loss 2.62 -- Perplexity 13.80\n",
            "----- Step 13400 -- Loss 2.74 -- Perplexity 15.48\n",
            "----- Step 13500 -- Loss 2.66 -- Perplexity 14.37\n",
            "----- Step 13600 -- Loss 2.67 -- Perplexity 14.50\n",
            "Training: 100% 402/402 [15:20<00:00,  1.99s/it]\n",
            "Epoch finished in 0:15:20.965811\n",
            "\n",
            "----- Epoch 35/35 ; (lr=0.002) -----\n",
            "Shuffling the dataset...\n",
            "----- Step 13700 -- Loss 2.60 -- Perplexity 13.45\n",
            "----- Step 13800 -- Loss 2.69 -- Perplexity 14.68\n",
            "----- Step 13900 -- Loss 2.69 -- Perplexity 14.72\n",
            "----- Step 14000 -- Loss 2.68 -- Perplexity 14.54\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "Training: 100% 402/402 [15:28<00:00,  2.02s/it]\n",
            "Epoch finished in 0:15:28.815334\n",
            "Checkpoint reached: saving model (don't stop the run)...\n",
            "Model saved.\n",
            "The End! Thanks for using this program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9-L8KodQeJ-",
        "colab_type": "code",
        "outputId": "c705491d-00d4-4087-a59a-194c4a0c4810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py --test"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to DeepQA v0.1 !\n",
            "\n",
            "TensorFlow detected: v1.15.0\n",
            "\n",
            "Warning: Restoring parameters:\n",
            "globStep: 14070\n",
            "watsonMode: False\n",
            "autoEncode: False\n",
            "corpus: cornell\n",
            "datasetTag: \n",
            "maxLength: 20\n",
            "filterVocab: 1\n",
            "skipLines: False\n",
            "vocabularySize: 40000\n",
            "hiddenSize: 512\n",
            "numLayers: 2\n",
            "softmaxSamples: 0\n",
            "initEmbeddings: False\n",
            "embeddingSize: 128\n",
            "embeddingSource: GoogleNews-vectors-negative300.bin\n",
            "\n",
            "Loading dataset from /content/data/samples/dataset-cornell-length20-filter1-vocabSize40000.pkl\n",
            "Loaded cornell: 34069 words, 205566 QA\n",
            "Model creation...\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:145: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:155: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:161: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2019-12-10 03:01:31.301319: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/legacy_seq2seq/python/ops/seq2seq.py:363: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/core_rnn_cell.py:104: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:173: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:174: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-12-10 03:01:32.721529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2019-12-10 03:01:32.721816: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2dc3100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-10 03:01:32.721850: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-10 03:01:32.724008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-10 03:01:32.797035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.798018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2dc32c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-10 03:01:32.798073: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-12-10 03:01:32.798271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.798900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-10 03:01:32.799286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-10 03:01:32.801071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-10 03:01:32.813891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-10 03:01:32.814228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-10 03:01:32.816568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-10 03:01:32.831701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-10 03:01:32.855465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-10 03:01:32.855625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.856293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.856868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-10 03:01:32.856941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-10 03:01:32.858418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-10 03:01:32.858449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-10 03:01:32.858462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-10 03:01:32.858618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.859319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:01:32.860074: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-10 03:01:32.860125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Initialize variables...\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:192: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "Start predicting...\n",
            "Restoring previous model from /content/save/model/model.ckpt\n",
            "Testing...\n",
            "Sentences:   0% 0/328 [00:00<?, ?it/s]2019-12-10 03:01:33.913469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Sentences: 100% 328/328 [00:37<00:00,  8.81it/s]\n",
            "Prediction finished, 0/328 sentences ignored (too long)\n",
            "All predictions done\n",
            "The End! Thanks for using this program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oltIqWwAtkyf",
        "colab_type": "code",
        "outputId": "925e363c-9848-4cdd-cd0b-0ffdc700571d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python main.py --test interactive"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to DeepQA v0.1 !\n",
            "\n",
            "TensorFlow detected: v1.15.0\n",
            "\n",
            "Warning: Restoring parameters:\n",
            "globStep: 14070\n",
            "watsonMode: False\n",
            "autoEncode: False\n",
            "corpus: cornell\n",
            "datasetTag: \n",
            "maxLength: 20\n",
            "filterVocab: 1\n",
            "skipLines: False\n",
            "vocabularySize: 40000\n",
            "hiddenSize: 512\n",
            "numLayers: 2\n",
            "softmaxSamples: 0\n",
            "initEmbeddings: False\n",
            "embeddingSize: 128\n",
            "embeddingSource: GoogleNews-vectors-negative300.bin\n",
            "\n",
            "Loading dataset from /content/data/samples/dataset-cornell-length20-filter1-vocabSize40000.pkl\n",
            "Loaded cornell: 34069 words, 205566 QA\n",
            "Model creation...\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:145: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:155: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/chatbot/model.py:161: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "2019-12-10 03:08:07.124029: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/legacy_seq2seq/python/ops/seq2seq.py:363: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/core_rnn_cell.py:104: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:173: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:174: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:182: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-12-10 03:08:08.551194: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2019-12-10 03:08:08.551450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x185f100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-10 03:08:08.551494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-12-10 03:08:08.553319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-12-10 03:08:08.632670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.633517: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x185f2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-12-10 03:08:08.633545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-12-10 03:08:08.633807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.634427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-12-10 03:08:08.634840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-10 03:08:08.636716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2019-12-10 03:08:08.638906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2019-12-10 03:08:08.639268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2019-12-10 03:08:08.641939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2019-12-10 03:08:08.643081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2019-12-10 03:08:08.649929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-12-10 03:08:08.650088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.650968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.651675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-12-10 03:08:08.651754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2019-12-10 03:08:08.653337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-12-10 03:08:08.653374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-12-10 03:08:08.653406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-12-10 03:08:08.653626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.654396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-12-10 03:08:08.655100: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-12-10 03:08:08.655164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Initialize variables...\n",
            "WARNING:tensorflow:From /content/chatbot/chatbot.py:192: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING: Restoring previous model from /content/save/model/model.ckpt\n",
            "Testing: Launch interactive mode:\n",
            "\n",
            "Welcome to the interactive mode, here you can ask to Deep Q&A the sentence you want. Don't have high expectation. Type 'exit' or just press ENTER to quit the program. Have fun.\n",
            "Q: what are you doing?\n",
            "2019-12-10 03:08:21.803846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "A: I'm going to see you.\n",
            "\n",
            "Q: I will kill you.\n",
            "A: I'm not going to hurt you.\n",
            "\n",
            "Q: Listen to me.\n",
            "A: I'll be right back.\n",
            "\n",
            "Q: where are you going?\n",
            "A: I'm going to see you.\n",
            "\n",
            "Q: what is your name?\n",
            "A: O'grady.\n",
            "\n",
            "Q: are you a human>\n",
            "A: Shhhhhh, quiet.\n",
            "\n",
            "Q: are you a human?\n",
            "A: Two and counting.\n",
            "\n",
            "Q: one plus one?\n",
            "A: Yeah. i was just wondering.\n",
            "\n",
            "Q: who created you?\n",
            "A: I'm a man.\n",
            "\n",
            "Q: are you a man?\n",
            "A: Yes.\n",
            "\n",
            "Q: are you kidding me?\n",
            "A: No, i'm not.\n",
            "\n",
            "Q: you are a murderer.\n",
            "A: I'm not.\n",
            "\n",
            "Q: I want your attention.\n",
            "A: I'm sorry.\n",
            "\n",
            "Q: Can you please help me?\n",
            "A: I'm not sure.\n",
            "\n",
            "Q: help me!\n",
            "A: I'm not going to hurt you.\n",
            "\n",
            "Q: shut up\n",
            "A: I'm sorry, i'm not going to get you out of here.\n",
            "\n",
            "Q: shut up.\n",
            "A: I'm sorry.\n",
            "\n",
            "Q: what do you do all the day.\n",
            "A: You're not going to be a little bit.\n",
            "\n",
            "Q: where do you live\n",
            "A: I'm going to see you.\n",
            "\n",
            "Q: where do you live.\n",
            "A: I do n't know.\n",
            "\n",
            "Q: are you a machine?\n",
            "A: No. i'm not.\n",
            "\n",
            "Q: The universe will end.\n",
            "A: The perpetrator.\n",
            "\n",
            "Q: Everything has an end.\n",
            "A: Tsi tien, chien-penny.\n",
            "\n",
            "Q: The world will collapse.\n",
            "A: It's not a joke.\n",
            "\n",
            "Q: are you kidding me?\n",
            "A: No, i'm not.\n",
            "\n",
            "Q: Traceback (most recent call last):\n",
            "  File \"main.py\", line 29, in <module>\n",
            "    chatbot.main()\n",
            "  File \"/content/chatbot/chatbot.py\", line 204, in main\n",
            "  File \"/content/chatbot/chatbot.py\", line 328, in mainTestInteractive\n",
            "    question = input(self.SENTENCES_PREFIX[0])\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXRJiTGttlb2",
        "colab_type": "code",
        "outputId": "277e7051-d31f-4bdd-be9c-b975fc8450e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hzapQ9P8-cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp modelTrained/ /content/gdrive/'My Drive'/ -r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zAGEMV9-tcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toZluVlhzcik",
        "colab_type": "text"
      },
      "source": [
        "#Loading Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwdllhHnzgEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp /content/gdrive/'My Drive'/modelTrained/  /content/ -r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTF6PoHOz0cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}